{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time  # time 모듈을 사용하여 지연을 추가\n",
    "import random  # 랜덤한 지연을 주기 위해 사용\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CVPR 2024 논문 목록 페이지 URL 설정\n",
    "cvpr_url = \"https://openaccess.thecvf.com/CVPR2024?day=all\"\n",
    "\n",
    "# 페이지 요청\n",
    "response = requests.get(cvpr_url)\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Failed to load page {}\".format(cvpr_url))\n",
    "\n",
    "# BeautifulSoup으로 HTML 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "382it [16:49,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve paper at https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SportsSloMo_A_New_Benchmark_and_Baselines_for_Human-centric_Video_Frame_CVPR_2024_paper.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1199it [55:25,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve paper at https://openaccess.thecvf.com/content/CVPR2024/html/Soucek_GenHowTo_Learning_to_Generate_Actions_and_State_Transformations_from_Instructional_CVPR_2024_paper.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2716it [2:06:21,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVPR 2024 논문 정보가 CSV 파일로 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 논문 정보를 담을 리스트 초기화\n",
    "papers = []\n",
    "\n",
    "# 논문 정보가 담긴 태그 추출 (예시: 논문 제목은 h5 태그, 저자 정보와 초록이 따로 있는 경우 등)\n",
    "for i, paper in tqdm(enumerate(soup.find_all('dt'))):\n",
    "\n",
    "    # 각 논문 상세 페이지로 이동하여 초록 정보 크롤링\n",
    "    paper_url = \"https://openaccess.thecvf.com\" + paper.find('a')['href']\n",
    "    \n",
    "    # 요청 사이에 지연을 추가 (1초에서 3초 사이의 랜덤 지연)\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    paper_response = requests.get(paper_url)\n",
    "    if paper_response.status_code != 200:\n",
    "        print(f\"Failed to retrieve paper at {paper_url}\")\n",
    "        continue\n",
    "    \n",
    "    paper_soup = BeautifulSoup(paper_response.text, 'html.parser')\n",
    "    \n",
    "    # 초록 정보 추출 (예시로 div 태그에서 abstract를 추출)\n",
    "    abstract = paper_soup.find('div', {'id': 'abstract'}).text.strip()\n",
    "    title = paper_soup.find('div', {'id': 'papertitle'}).text.strip()\n",
    "    url = \"https://openaccess.thecvf.com\" + paper_soup.find('a', string='pdf')['href'].strip()\n",
    "    \n",
    "    # 논문 정보 저장\n",
    "    papers.append({\n",
    "        'title': title,\n",
    "        'abstract': abstract,\n",
    "        'url': paper_url\n",
    "    })\n",
    "\n",
    "    if (i != 0) and (i % 200 == 0):\n",
    "        # 200개씩 끊어서 논문 정보 저장\n",
    "        df = pd.DataFrame(papers)\n",
    "        df.to_csv('cvpr2024_papers-{}.csv'.format(str(i)), index=False)\n",
    "        papers = []\n",
    "\n",
    "\n",
    "# DataFrame으로 변환 후 CSV 저장\n",
    "df = pd.DataFrame(papers)\n",
    "df.to_csv('cvpr2024_papers.csv', index=False)\n",
    "\n",
    "print(\"CVPR 2024 논문 정보가 CSV 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cvpr2024_papers-200.csv',\n",
       " 'cvpr2024_papers-400.csv',\n",
       " 'cvpr2024_papers-600.csv',\n",
       " 'cvpr2024_papers-800.csv',\n",
       " 'cvpr2024_papers-1000.csv',\n",
       " 'cvpr2024_papers-1200.csv',\n",
       " 'cvpr2024_papers-1400.csv',\n",
       " 'cvpr2024_papers-1600.csv',\n",
       " 'cvpr2024_papers-1800.csv',\n",
       " 'cvpr2024_papers-2000.csv',\n",
       " 'cvpr2024_papers-2200.csv',\n",
       " 'cvpr2024_papers-2400.csv',\n",
       " 'cvpr2024_papers-2600.csv',\n",
       " 'cvpr2024_papers-2800.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort paper lists\n",
    "plist = [i for i in os.listdir('./') if 'cvpr2024' in i]\n",
    "plist.sort(key=lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "\n",
    "plist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unmixing Diffusion for Self-Supervised Hypersp...</td>\n",
       "      <td>Hyperspectral images (HSIs) have extensive app...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seeing the World through Your Eyes</td>\n",
       "      <td>The reflective nature of the human eye is an u...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPMesh: Exploiting Diffusion Prior for Occlude...</td>\n",
       "      <td>The recovery of occluded human meshes poses ch...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ungeneralizable Examples</td>\n",
       "      <td>The training of contemporary deep learning mod...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaneCPP: Continuous 3D Lane Detection using Ph...</td>\n",
       "      <td>Monocular 3D lane detection has become a funda...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Language-driven Object Fusion into Neural Radi...</td>\n",
       "      <td>Neural radiance field (NeRF) is an emerging te...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Adaptive Hyper-graph Aggregation for Modality-...</td>\n",
       "      <td>In Federated Learning (FL) the issue of statis...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SPIN: Simultaneous Perception Interaction and ...</td>\n",
       "      <td>While there has been remarkable progress recen...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>DREAM: Diffusion Rectification and Estimation-...</td>\n",
       "      <td>We present DREAM a novel training framework re...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Exploring the Potential of Large Foundation Mo...</td>\n",
       "      <td>Open-vocabulary human-object interaction (HOI)...</td>\n",
       "      <td>https://openaccess.thecvf.com/content/CVPR2024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2714 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Unmixing Diffusion for Self-Supervised Hypersp...   \n",
       "1                   Seeing the World through Your Eyes   \n",
       "2    DPMesh: Exploiting Diffusion Prior for Occlude...   \n",
       "3                             Ungeneralizable Examples   \n",
       "4    LaneCPP: Continuous 3D Lane Detection using Ph...   \n",
       "..                                                 ...   \n",
       "110  Language-driven Object Fusion into Neural Radi...   \n",
       "111  Adaptive Hyper-graph Aggregation for Modality-...   \n",
       "112  SPIN: Simultaneous Perception Interaction and ...   \n",
       "113  DREAM: Diffusion Rectification and Estimation-...   \n",
       "114  Exploring the Potential of Large Foundation Mo...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Hyperspectral images (HSIs) have extensive app...   \n",
       "1    The reflective nature of the human eye is an u...   \n",
       "2    The recovery of occluded human meshes poses ch...   \n",
       "3    The training of contemporary deep learning mod...   \n",
       "4    Monocular 3D lane detection has become a funda...   \n",
       "..                                                 ...   \n",
       "110  Neural radiance field (NeRF) is an emerging te...   \n",
       "111  In Federated Learning (FL) the issue of statis...   \n",
       "112  While there has been remarkable progress recen...   \n",
       "113  We present DREAM a novel training framework re...   \n",
       "114  Open-vocabulary human-object interaction (HOI)...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "1    https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "2    https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "3    https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "4    https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "..                                                 ...  \n",
       "110  https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "111  https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "112  https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "113  https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "114  https://openaccess.thecvf.com/content/CVPR2024...  \n",
       "\n",
       "[2714 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, f in enumerate(plist):\n",
    "    f_ = pd.read_csv(f)\n",
    "    if i == 0:\n",
    "        merged_f = f_\n",
    "    else:\n",
    "        merged_f = pd.concat([merged_f, f_], axis=0)\n",
    "\n",
    "merged_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_f.to_csv('cvpr2024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
